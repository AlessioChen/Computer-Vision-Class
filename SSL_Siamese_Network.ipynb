{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessioChen/Computer-Vision-Class/blob/main/SSL_Siamese_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg7BGBFjv5SP"
      },
      "source": [
        "# Siamese Network\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In this session, we are going to implement a Siamese Network.\n",
        "\n",
        "It takes as input two augmented versions of the same image and produces as output two feature vectors one for each version of the image.\n",
        "\n",
        "For simplicity, we will use the same backbone to process the views as in SimCLR paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wnoJ4nz6t3rN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G44sBdg5xSA3"
      },
      "outputs": [],
      "source": [
        "# you can use a resnet18 as backbone\n",
        "backbone = models.resnet18()\n",
        "#! remember to delete the fc layer (we need just the CNN layers + flatten)\n",
        "backbone.fc = torch.nn.Identity()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEu_h8dhx8Lz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2944c6fd-5ddb-4424-c53f-351141f7deab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 512]) torch.Size([0, 512])\n"
          ]
        }
      ],
      "source": [
        "class SiameseNetSymmetric(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = backbone\n",
        "        self.encoder.fc = torch.nn.Identity()\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x = torch.concat((x1 , x2), dim=0)\n",
        "        x = self.encoder(x)\n",
        "\n",
        "        f1 = x[:x.shape[0]]\n",
        "        f2 = x[x.shape[0]:]\n",
        "\n",
        "        return f1, f2\n",
        "\n",
        "\n",
        "# Check output shape\n",
        "model = SiameseNetSymmetric(backbone)\n",
        "f1, f2 = model(torch.randn(5, 3, 32, 32), torch.randn(5, 3, 32, 32))\n",
        "print(f1.shape, f2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetAsymmetric(nn.Module):\n",
        "    def __init__(self, backbone):\n",
        "        super().__init__()\n",
        "        self.encoder1 = backbone\n",
        "        self.encoder1.fc = torch.nn.Identity()\n",
        "\n",
        "        self.encoder2 = backbone\n",
        "        self.encoder2.fc = torch.nn.Identity()\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "\n",
        "        f1 = self.encoder1(x1)\n",
        "        f2 = self.encoder2(x2)\n",
        "\n",
        "        return f1, f2\n",
        "\n",
        "\n",
        "# Check output shape\n",
        "model = SiameseNetAsymmetric(backbone)\n",
        "f1, f2 = model(torch.randn(5, 3, 32, 32), torch.randn(5, 3, 32, 32))\n",
        "print(f1.shape, f2.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTDlIunnnn3f",
        "outputId": "34197e64-393d-4006-cf0f-a4b3137fc97f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5, 512]) torch.Size([5, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RlyBgKKzyxyB"
      },
      "source": [
        "Let's now use the Dataset which creates the two augmented views for each image from the [past lab session](https://colab.research.google.com/drive/1NJwAFbRiD4MdwWf__6P2Lm0xYk_DNdVu?usp=sharing) and create a loop with forward pass"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SSLDataset(Dataset):\n",
        "    def __init__(self, dataset, transform=None):\n",
        "        self.dataset = dataset\n",
        "        self.transform = transform\n",
        "\n",
        "        self.imgs = dataset.data\n",
        "        self.targets = dataset.targets\n",
        "\n",
        "        self.id = 0\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.dataset[idx]\n",
        "\n",
        "        if self.transform:\n",
        "          img1 = self.transform(image)\n",
        "          img2 = self.transform(image)\n",
        "\n",
        "        else:\n",
        "          img1 = image\n",
        "          img2 = image\n",
        "\n",
        "        label1 = label2 = self.id\n",
        "\n",
        "        self.id += 1\n",
        "        # same id = positive pair\n",
        "        return img1, img2, label1, label2"
      ],
      "metadata": {
        "id": "C_G-sMVsi8_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True)\n",
        "\n",
        "# simclr DA pipeline\n",
        "s=1\n",
        "size = 32\n",
        "color_jitter = transforms.ColorJitter(0.8 * s, 0.8 * s, 0.8 * s, 0.2 * s)\n",
        "transform = transforms.Compose([transforms.RandomResizedCrop(size=size),\n",
        "                                  transforms.RandomHorizontalFlip(),\n",
        "                                  transforms.RandomApply([color_jitter], p=0.8),\n",
        "                                  transforms.RandomGrayscale(p=0.2),\n",
        "                                  transforms.GaussianBlur(kernel_size=int(0.1 * size)),\n",
        "                                  transforms.ToTensor()])\n",
        "\n",
        "# create training set from CustomDataset\n",
        "trainset = SSLDataset(dataset = dataset, transform=transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmAc6aoXjC7u",
        "outputId": "dcfe8301-644f-4794-e040-36e8154e59a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:02<00:00, 80.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contrastive loss\n",
        "\n",
        "Obiettivo: massimizzare negative log likelihood delle similutidine tra le classi negative"
      ],
      "metadata": {
        "id": "xXufF3bBj4bI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, features):\n",
        "        ### features = torch.cat((x1,x2), dim=0)\n",
        "        # normalize features to later compute cosine distance/similarity btw them\n",
        "        features = F.normalize(features, dim=1)\n",
        "\n",
        "        # compute the similarity matrix btw features\n",
        "        N = features.shape[0] # 2 * batch size\n",
        "        batch_size = N / 2\n",
        "        features = nn.functional.normalize(features, dim=1)\n",
        "        # compute the similarity matrix btw features\n",
        "        # (consider that feature are normalized! so the cosine similarity is ...)\n",
        "        similarity_matrix = torch.matmul(features, features.T)\n",
        "\n",
        "        # create the logits tensor where:\n",
        "        #   - in the first position there is the similarity of the positive pair\n",
        "        #   - in the other 2N-1 positions there are the similarity w negatives\n",
        "        # the shape of the tensor need to be 2Nx2N-1, with N is the batch size\n",
        "        logits = torch.zeros((N , N - 1))\n",
        "\n",
        "        for idx, val in enumerate(similarity_matrix):\n",
        "          row = torch.zeros(N - 1)\n",
        "\n",
        "          pos_idx = idx + batch_size if idx < batch_size else idx - batch_size\n",
        "          row[0] = val[pos_idx]   # positive in first position\n",
        "          row[1:] = torch.tensor([v for i, v in enumerate(val) if i != idx and i != pos_idx])\n",
        "\n",
        "          logits[idx] = row\n",
        "\n",
        "        logits /= self.temperature\n",
        "        gt = torch.zeros(logits.shape[0], dtype=torch.long) # positive in first position\n",
        "\n",
        "        # to compute the contrastive loss using the CE loss, we just need to\n",
        "        # specify where is the similarity of the positive pair in the logits tensor\n",
        "        # since we put in the first position we create a gt of all zeros\n",
        "        # N.B.: this is just one of the possible implementations!\n",
        "        loss = self.criterion(logits, gt)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "gCoMlhtnkdbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "labels = torch.cat([torch.arange(5) for i in range(2)], dim=0)  #0,1,2, N-1 | 0,1,2 N-1 -> label associata ad ogni elemento\n",
        "print(labels)\n",
        "labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float() # diagonale identità + sotto identità\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Mwbl91hVSx",
        "outputId": "137b4977-38d3-447b-f419-668298549a1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([[1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
            "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
            "        [0., 1., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
            "        [0., 0., 1., 0., 0., 0., 0., 1., 0., 0.],\n",
            "        [0., 0., 0., 1., 0., 0., 0., 0., 1., 0.],\n",
            "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn import functional as F\n",
        "class ContrastiveLoss2(nn.Module):\n",
        "    def __init__(self, temperature=0.07):\n",
        "        super().__init__()\n",
        "        self.temperature = temperature\n",
        "        self.criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    def forward(self, features):\n",
        "        batch_size = features.shape[0] // 2\n",
        "        features = F.normalize(features, dim = 1)\n",
        "        similarity_matrix = torch.matmul(features, features.T)\n",
        "\n",
        "        labels = torch.cat([torch.arange(batch_size) for i in range(2)], dim=0)  #0,1,2, N-1 | 0,1,2 N-1 -> label associata ad ogni elemento\n",
        "        labels = (labels.unsqueeze(0) == labels.unsqueeze(1)).float()\n",
        "        mask = torch.eye(labels.shape[0], dtype=torch.bool)\n",
        "        labels = labels[~mask].view(labels.shape[0], -1)\n",
        "        similarity_matrix = similarity_matrix[~mask].view(similarity_matrix.shape[0], -1)\n",
        "\n",
        "        positives = similarity_matrix[labels.bool()].view(similarity_matrix.shape[0], -1)\n",
        "        negatives = similarity_matrix[~labels.bool()].view(similarity_matrix.shape[0], -1)\n",
        "\n",
        "        logits = torch.cat(positives, negatives, dim=1)\n",
        "        logits /= self.temperature\n",
        "        gt = torch.zeros(logits.shape[0], dtype=torch.long) # positive in first position\n",
        "        loss = self.criterion(logits, gt)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "ce4m3yOMgShq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NJAgRkIzyUTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "1a4e0c6a-09a4-4cba-e137-687c26bdde4a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "only integers, slices (`:`), ellipsis (`...`), None and long or byte Variables are valid indices (got float)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-1e73ea8ebd19>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# backprop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-64-53d495fefbd5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0mpos_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m           \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m           \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mpos_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), None and long or byte Variables are valid indices (got float)"
          ]
        }
      ],
      "source": [
        "\n",
        "dataloader = DataLoader(trainset, batch_size=64, shuffle=True)\n",
        "\n",
        "model = SiameseNetSymmetric(backbone)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = ContrastiveLoss()\n",
        "\n",
        "\n",
        "for idx, data in enumerate(dataloader):\n",
        "    img1, img2, _ , _ = data\n",
        "\n",
        "\n",
        "    f1, f2 = model(img1, img2)\n",
        "    # loss (f1, f2)\n",
        "\n",
        "    features = torch.cat((f1, f2), dim=0)\n",
        "    output = criterion(features)\n",
        "    break\n",
        "    # backprop\n",
        "\n",
        "    # optimizer.zero_grad()\n",
        "    # output = model(images)\n",
        "    # loss = criterion(output, target)\n",
        "    # loss.backward()\n",
        "    # optimizer.step()\n",
        "\n",
        "    if idx == 3:\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xMrODxPswgFf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}