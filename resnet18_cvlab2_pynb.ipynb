{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "nsQc2Ya4wfGx"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN83o1pV5F7A1tzul4Nyu/G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessioChen/Computer-Vision-Class/blob/main/resnet18_cvlab2_pynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eEVwxmAfwUHs",
        "outputId": "6cce7d7e-9db8-4daf-811f-9cddc4cb08dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from torchinfo import summary\n",
        "from torch.optim.lr_scheduler import ExponentialLR, MultiStepLR\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils"
      ],
      "metadata": {
        "id": "nsQc2Ya4wfGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "!pip install wandb -qU\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkNH6UMHwXsi",
        "outputId": "96c47163-e435-4080-bdb3-8309db029e7f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(optimizer):\n",
        "    for param_group in optimizer.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "p1WDt65TwpW5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_trainable_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
      ],
      "metadata": {
        "id": "KHYg_tEuwqvx"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, device, train_loader, criterion, optimizer):\n",
        "    model.train()  # training mode\n",
        "\n",
        "    losses, accs = [], []\n",
        "    correct = 0.\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        ## zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        ## forward + backward + optimize\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        ## Prediction\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        correct = torch.eq(pred, target.view_as(pred)).float()\n",
        "        acc = torch.mean(correct)\n",
        "\n",
        "        losses.append(loss.detach().cpu().numpy())\n",
        "        accs.append(acc.detach().cpu().numpy())\n",
        "\n",
        "    loss_k = np.array(losses).mean()\n",
        "    acc_k = np.array(accs).mean()\n",
        "\n",
        "    return loss_k, acc_k"
      ],
      "metadata": {
        "id": "aiVqd5BRwrxy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, device, criterion, test_loader):\n",
        "    model.eval()  # evaluation mode\n",
        "\n",
        "    losses, accs = [], []\n",
        "    correct = 0.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            ## Compute loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            ## Prediction\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct = torch.eq(pred, target.view_as(pred)).float()\n",
        "            # correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "            acc = torch.mean(correct)\n",
        "\n",
        "            ## Update loss and accuracy\n",
        "            losses.append(loss.detach().cpu().numpy())\n",
        "            accs.append(acc.detach().cpu().numpy())\n",
        "\n",
        "    loss_k = np.array(losses).mean()\n",
        "    acc_k = np.array(accs).mean()\n",
        "\n",
        "    return loss_k, acc_k"
      ],
      "metadata": {
        "id": "E9pUUlCAwta0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_loop(train_loader, test_loader, model, criterion, device,\n",
        "               lr, momentum, max_epochs, do_test=True):\n",
        "    \"\"\"\" Training loop with SGD \"\"\"\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    losses_train, accs_train = [], []\n",
        "    losses_test, accs_test = [], []\n",
        "\n",
        "    _start = time.time()\n",
        "    _epoch_time = time.time()\n",
        "\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        loss_train, acc_train = train(model, device, train_loader, criterion, optimizer)\n",
        "        print(f\"Epoch: {epoch}, Learning rate: {get_lr(optimizer):.6f}\")\n",
        "        print(f\"Training - Loss: {loss_train:.4f}, Accuracy: {acc_train:.2f}, Runtime: {(time.time() - _epoch_time):.2f}\")\n",
        "        losses_train.append(loss_train)\n",
        "        accs_train.append(acc_train)\n",
        "\n",
        "        if do_test:\n",
        "            loss_test, acc_test = test(model, device, criterion, test_loader)\n",
        "            losses_test.append(loss_test)\n",
        "            accs_test.append(acc_test)\n",
        "            print(f\"Test - Loss: {loss_test:.4f}, Accuracy: {acc_test:.2f}\")\n",
        "\n",
        "        _epoch_time = time.time()\n",
        "\n",
        "    _end = time.time()\n",
        "    print(f\"Done! - Runtime: {(_end-_start):.2f} seconds\")\n",
        "\n",
        "    # test_class(model, device, criterion, testloader)\n",
        "\n",
        "    if do_test:\n",
        "        return losses_train, accs_train, losses_test, accs_test\n",
        "    else:\n",
        "        return losses_train, accs_train"
      ],
      "metadata": {
        "id": "8Uq6SXDswuxk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop_sched(train_loader, test_loader, model, criterion, device,\n",
        "                     optimizer, scheduler=None, max_epochs=10, do_test=True):\n",
        "    \"\"\" Training loop with custom optimizer and optional learning rate scheduler \"\"\"\n",
        "\n",
        "    losses_train, accs_train = [], []\n",
        "    losses_test, accs_test = [], []\n",
        "\n",
        "    _start = time.time()\n",
        "    _epoch_time = time.time()\n",
        "\n",
        "    # init of wandb\n",
        "    wandb.init(\n",
        "      project='cv-lab2',\n",
        "      config= {\n",
        "          \"learning_rate\": get_lr(optimizer),\n",
        "          \"dataset\": \"CIFAR10\",\n",
        "          \"architecture\": \"ResNet18\",\n",
        "          \"epochs\": max_epochs,\n",
        "      },\n",
        "      entity='alessiochen98-university-of-florence',\n",
        "      name='reset18'\n",
        "    )\n",
        "\n",
        "    # epoch number only for logging\n",
        "    for epoch in range(1, max_epochs + 1):\n",
        "        ## Training\n",
        "        loss_train, acc_train = train(model, device, train_loader, criterion, optimizer)\n",
        "        print(f\"Epoch: {epoch}, Learning rate: {get_lr(optimizer):.6f}\")\n",
        "        print(f\"Training - Loss: {loss_train:.4f}, Accuracy: {acc_train:.3f}, Runtime: {(time.time() - _epoch_time):.2f}\")\n",
        "\n",
        "        wandb.log({\n",
        "            \"train_loss\": loss_train,\n",
        "            \"train_accuracy\": acc_train,\n",
        "        })\n",
        "\n",
        "        losses_train.append(loss_train)\n",
        "        accs_train.append(acc_train)\n",
        "        # Learning rate scheduler\n",
        "        if scheduler is not None:\n",
        "            scheduler.step()\n",
        "        ## Test/Validation\n",
        "        if do_test:\n",
        "            loss_test, acc_test = test(model, device, criterion, test_loader)\n",
        "            losses_test.append(loss_test)\n",
        "            accs_test.append(acc_test)\n",
        "            print(f\"Test - Loss: {loss_test:.4f}, Accuracy: {acc_test:.3f}\")\n",
        "\n",
        "            wandb.log({\n",
        "              \"test_loss\": loss_train,\n",
        "              \"test_accuracy\": acc_train,\n",
        "            })\n",
        "\n",
        "        _epoch_time = time.time()\n",
        "\n",
        "    _end = time.time()\n",
        "    print(f\"Done! - Runtime: {(_end-_start):.2f} seconds\")\n",
        "\n",
        "    if do_test:\n",
        "        return losses_train, accs_train, losses_test, accs_test\n",
        "    else:\n",
        "        return losses_train, accs_train\n"
      ],
      "metadata": {
        "id": "0vAVOKmAwwXw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_class(model, device, criterion, test_loader, classes):\n",
        "    model.eval()  # configura il modello in evaluation mode\n",
        "\n",
        "    # prepare to count predictions for each class\n",
        "    correct_pred = {classname: 0 for classname in classes}\n",
        "    total_pred = {classname: 0 for classname in classes}\n",
        "\n",
        "    # prepare to count overall predictions\n",
        "    losses, accs = [], []\n",
        "    correct = 0.\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            ## Fit data and compute loss\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "\n",
        "            ## Prediction\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "\n",
        "            # compute overall accuracy\n",
        "            correct = torch.eq(pred, target.view_as(pred)).float()\n",
        "            acc = torch.mean(correct)\n",
        "            # update loss and accuracy\n",
        "            losses.append(loss.detach().cpu().numpy())\n",
        "            accs.append(acc.detach().cpu().numpy())\n",
        "\n",
        "            for target_i, pred_i in zip(target, pred):\n",
        "                if target_i == pred_i:\n",
        "                    correct_pred[classes[target_i]] += 1\n",
        "                total_pred[classes[target_i]] += 1\n",
        "\n",
        "    loss_final = np.array(losses).mean()\n",
        "    acc_final = np.array(accs).mean()\n",
        "    print(f\"Final loss: {loss_final:.4f}, Accuracy: {acc_final:.3f}\")\n",
        "    print(\"-------\")\n",
        "\n",
        "    # print accuracy for each class\n",
        "    for classname, correct_count in correct_pred.items():\n",
        "        accuracy = 100 * float(correct_count) / total_pred[classname]\n",
        "        print(f'Accuracy for class: {classname:5s} is {accuracy:.1f} %')"
      ],
      "metadata": {
        "id": "FdZzla5Aw7fz"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_diagnostic(max_epochs, losses_train, accs_train):\n",
        "    epochs_seq = np.arange(1, max_epochs + 1)\n",
        "    # epoch_labels =\n",
        "\n",
        "    # plot only training loss and accuracy\n",
        "    fig, ax = plt.subplots()\n",
        "    # fig.suptitle(\"Training performance\")\n",
        "    fig.suptitle(\"Training loss and accuracy againts epochs\")\n",
        "\n",
        "    color = \"tab:blue\"\n",
        "    ax.plot(epochs_seq, losses_train, label=\"loss\", color=color)\n",
        "    # ax.set_title(\"Training loss and accuracy againts epochs\")\n",
        "    ax.grid(\"both\")\n",
        "    ax.set_xlabel(\"Epochs\")\n",
        "    ax.set_ylabel(\"Loss\", color=color)\n",
        "    ax.tick_params(axis=\"y\", labelcolor=color)\n",
        "    ax.set_xticks(np.arange(1, max_epochs+1, step=2))\n",
        "    ax.set_xticklabels(np.arange(1, max_epochs + 1, 2))\n",
        "\n",
        "    color = \"tab:red\"\n",
        "    ax_1 = ax.twinx()\n",
        "    ax_1.plot(epochs_seq, accs_train, label=\"accuracy\", color=\"tab:red\")\n",
        "    ax_1.set_ylabel(\"Accuracy\", color=\"tab:red\")\n",
        "    ax_1.tick_params(axis=\"y\", labelcolor=color)"
      ],
      "metadata": {
        "id": "eupSRyGQw-pm"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnostic(losses_train, accs_train, losses_test, accs_test):\n",
        "    ## left side training performance\n",
        "    ## right side test performance\n",
        "    max_epochs = len(losses_train)\n",
        "    epochs_seq = np.arange(1, max_epochs + 1)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), layout=\"constrained\")\n",
        "    fig.suptitle(\"CNN performance over MNIST\")\n",
        "\n",
        "    ## 1) train loss (first y axis) and accuracy (second y axis)\n",
        "    color = \"tab:blue\"\n",
        "    axs[0].plot(epochs_seq, losses_train, label=\"loss\", color=color)\n",
        "    axs[0].set_title(\"Training loss and accuracy againts epochs\")\n",
        "    axs[0].grid(\"both\")\n",
        "    axs[0].set_xlabel(\"Epochs\")\n",
        "    axs[0].set_ylabel(\"Loss\", color=color)\n",
        "    axs[0].tick_params(axis=\"y\", labelcolor=color)\n",
        "\n",
        "    color = \"tab:red\"\n",
        "    axs0_1 = axs[0].twinx()\n",
        "    axs0_1.plot(epochs_seq, accs_train, label=\"accuracy\", color=\"tab:red\")\n",
        "    axs0_1.set_ylabel(\"Accuracy\", color=\"tab:red\")\n",
        "    axs0_1.tick_params(axis=\"y\", labelcolor=color)\n",
        "\n",
        "    ## 2) test loss (first y axis) and accuracy (second y axis)\n",
        "    color = \"tab:blue\"\n",
        "    axs[1].plot(epochs_seq, losses_test, label=\"loss\", color=color)\n",
        "    axs[1].set_title(\"Test loss and accuracy againts epochs\")\n",
        "    axs[1].grid(\"both\")\n",
        "    axs[1].set_xlabel(\"Epochs\")\n",
        "    axs[1].set_ylabel(\"Loss\", color=color)\n",
        "    axs[1].tick_params(axis=\"y\", labelcolor=color)\n",
        "\n",
        "    color = \"tab:red\"\n",
        "    axs1_1 = axs[1].twinx()\n",
        "    axs1_1.plot(epochs_seq, accs_test, label=\"accuracy\", color=\"tab:red\")\n",
        "    axs1_1.set_ylabel(\"Accuracy\", color=\"tab:red\")\n",
        "    axs1_1.tick_params(axis=\"y\", labelcolor=color)"
      ],
      "metadata": {
        "id": "XvTc_RKYw-9R"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_diagnostic_single(loss_acc_dict, max_epochs=10):\n",
        "    # loss_acc_dict = {\"Solver1\": [loss, acc]...}\n",
        "    epochs_seq = np.arange(1, max_epochs + 1)\n",
        "    colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown']\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax_1 = ax.twinx()\n",
        "    # fig.suptitle(\"CNN training performance over CIFAR10\")\n",
        "    fig.suptitle(\"Training loss and accuracy againts epochs\")\n",
        "\n",
        "    for i, (solver_name, perf) in enumerate(loss_acc_dict.items()):\n",
        "\n",
        "        color = colors[i]\n",
        "        ## plot loss function performance\n",
        "        ax.plot(epochs_seq, perf[0], label=solver_name, color=color)\n",
        "        ax.grid(\"both\")\n",
        "        ax.set_xlabel(\"Epochs\")\n",
        "        ax.set_ylabel(\"Loss\")\n",
        "        ax.tick_params(axis=\"y\")\n",
        "        ax.set_xticks(np.arange(1, max_epochs+1, step=2))\n",
        "        ax.set_xticklabels(np.arange(1, max_epochs + 1, 2))\n",
        "\n",
        "        ## plot accuracy performance\n",
        "        ax_1.plot(epochs_seq, perf[1], label=solver_name, color=color)\n",
        "        ax_1.set_ylabel(\"Accuracy\")\n",
        "        ax_1.tick_params(axis=\"y\")\n",
        "\n",
        "    ax.legend()\n"
      ],
      "metadata": {
        "id": "gsvPEZZWxCHC"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def multiple_diagnostic(loss_acc_dict, max_epochs=None, title_left=\"Training loss against epochs\",\n",
        "                        title_right=\"Test accuracy against epochs\", fig_title=\"\"):\n",
        "    # loss_acc_dict = {\"Solver1\": [loss, acc]...}\n",
        "\n",
        "    if max_epochs is None:\n",
        "        max_epochs = len(next(iter(loss_acc_dict.values()))[0])\n",
        "        # print(max_epochs)\n",
        "\n",
        "    epochs_seq = np.arange(1, max_epochs + 1)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 2, figsize=(12, 4), layout=\"constrained\")\n",
        "    fig.suptitle(fig_title)\n",
        "\n",
        "    for solver_name, perf in loss_acc_dict.items():\n",
        "\n",
        "        # plot loss function performance\n",
        "        axs[0].plot(epochs_seq, perf[0], label=solver_name)\n",
        "        axs[0].grid(\"both\")\n",
        "        axs[0].set_title(title_left)\n",
        "        # axs[0].set_xlabel(\"Epochs\")\n",
        "        # axs[0].set_ylabel(\"Loss\")\n",
        "        axs[0].tick_params(axis=\"y\")\n",
        "        axs[0].set_xticks(np.arange(1, max_epochs+1, step=2))\n",
        "        axs[0].set_xticklabels(np.arange(1, max_epochs+1, 2))\n",
        "\n",
        "        # plot accuracy performance\n",
        "        axs[1].plot(epochs_seq, perf[1], label=solver_name)\n",
        "        axs[1].grid(\"both\")\n",
        "        axs[1].set_title(title_right)\n",
        "        # axs[1].set_xlabel(\"Epochs\")\n",
        "        # axs[1].set_ylabel(\"Accuracy\")\n",
        "        axs[1].tick_params(axis=\"y\")\n",
        "        axs[1].set_xticks(np.arange(1, max_epochs+1, step=2))\n",
        "        axs[1].set_xticklabels(np.arange(1, max_epochs+1, 2))\n",
        "\n",
        "    axs[0].legend()\n",
        "    axs[1].legend()\n"
      ],
      "metadata": {
        "id": "OqentEd9xDYb"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_json(loss_acc_dict, file_name):\n",
        "    \"\"\" Save diagnostic to JSON file for reuse \"\"\"\n",
        "    # loss_acc_dict: {\"Solver1\": [[list of np.float32], [list of np.float32]]}\n",
        "    # file_name: \"file_name.json\"\n",
        "\n",
        "    # convert to float for serialization\n",
        "    dict_converted = {k: [[float(x) for x in seq] for seq in v] for k, v in loss_acc_dict.items()}\n",
        "\n",
        "    with open(file_name, \"w\") as file:\n",
        "        json.dump(dict_converted, file)"
      ],
      "metadata": {
        "id": "6J_O1vjvxEqc"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5rucCYVQxItA"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resnet 18"
      ],
      "metadata": {
        "id": "idTJC44RxKdi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "head_loss_acc = {}"
      ],
      "metadata": {
        "id": "eQTMkNaMyELl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# batch_size = 64\n",
        "batch_size = 128\n",
        "max_epochs = 20\n",
        "\n",
        "opt_dict = dict(lr=0.01, momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "tM1Klt2-xVD2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),  # some augmentation\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    # transforms.Resize(224)\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "    # transforms.Resize(224)\n",
        "])\n",
        "\n",
        "dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform_train)\n",
        "\n",
        "# create a split for train/validation. We can use early stop\n",
        "trainset, valset = torch.utils.data.random_split(dataset, [40000, 10000])\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2,\n",
        "                                          drop_last=True, pin_memory=True)\n",
        "valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2,\n",
        "                                        drop_last=False, pin_memory=True)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2,\n",
        "                                         drop_last=False, pin_memory=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfmIorNdxW7a",
        "outputId": "7b2679cf-d130-4715-a3d8-274b2f573121"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 48.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet18 = models.resnet18(weights=\"DEFAULT\")\n",
        "\n",
        "resnet18.fc = nn.Linear(resnet18.fc.in_features, 10)\n",
        "resnet18 = resnet18.to(device)\n",
        "\n",
        "# print(summary(resnet18))\n",
        "print(f\"Trainable parameters: {count_trainable_parameters(resnet18)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7LAhml_xZFk",
        "outputId": "50d6eb37-160e-45fa-e064-1ccf6da78d25"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 79.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable parameters: 11181642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(resnet18.parameters(), **opt_dict)\n",
        "# scheduler = ExponentialLR(optimizer, 0.7)\n",
        "scheduler = MultiStepLR(optimizer, [5, 10, 15], 0.1)\n",
        "\n",
        "stats = train_loop_sched(trainloader, testloader, resnet18, criterion, device, optimizer, scheduler, max_epochs)\n",
        "\n",
        "head_loss_acc[\"Full\"] = [stats[0], stats[3]]\n",
        "\n",
        "print(\"=========\")\n",
        "test_class(resnet18, device, criterion, testloader, classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "D_flWlHhxlt9",
        "outputId": "1682cfb1-35d2-43fa-d82c-a0811202d8b5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.0"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241208_105536-rlfhj8cz</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/alessiochen98-university-of-florence/cv-lab2/runs/rlfhj8cz' target=\"_blank\">reset18</a></strong> to <a href='https://wandb.ai/alessiochen98-university-of-florence/cv-lab2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/alessiochen98-university-of-florence/cv-lab2' target=\"_blank\">https://wandb.ai/alessiochen98-university-of-florence/cv-lab2</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/alessiochen98-university-of-florence/cv-lab2/runs/rlfhj8cz' target=\"_blank\">https://wandb.ai/alessiochen98-university-of-florence/cv-lab2/runs/rlfhj8cz</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Learning rate: 0.010000\n",
            "Training - Loss: 1.0765, Accuracy: 0.628, Runtime: 29.60\n",
            "Test - Loss: 0.7949, Accuracy: 0.728\n",
            "Epoch: 2, Learning rate: 0.010000\n",
            "Training - Loss: 0.7372, Accuracy: 0.748, Runtime: 19.28\n",
            "Test - Loss: 0.6654, Accuracy: 0.775\n",
            "Epoch: 3, Learning rate: 0.010000\n",
            "Training - Loss: 0.6357, Accuracy: 0.781, Runtime: 20.67\n",
            "Test - Loss: 0.6191, Accuracy: 0.789\n",
            "Epoch: 4, Learning rate: 0.010000\n",
            "Training - Loss: 0.5793, Accuracy: 0.801, Runtime: 24.88\n",
            "Test - Loss: 0.5813, Accuracy: 0.802\n",
            "Epoch: 5, Learning rate: 0.010000\n",
            "Training - Loss: 0.5336, Accuracy: 0.815, Runtime: 19.24\n",
            "Test - Loss: 0.5768, Accuracy: 0.808\n",
            "Epoch: 6, Learning rate: 0.001000\n",
            "Training - Loss: 0.4311, Accuracy: 0.851, Runtime: 20.56\n",
            "Test - Loss: 0.4804, Accuracy: 0.838\n",
            "Epoch: 7, Learning rate: 0.001000\n",
            "Training - Loss: 0.3964, Accuracy: 0.863, Runtime: 19.09\n",
            "Test - Loss: 0.4684, Accuracy: 0.843\n",
            "Epoch: 8, Learning rate: 0.001000\n",
            "Training - Loss: 0.3780, Accuracy: 0.869, Runtime: 20.41\n",
            "Test - Loss: 0.4660, Accuracy: 0.843\n",
            "Epoch: 9, Learning rate: 0.001000\n",
            "Training - Loss: 0.3671, Accuracy: 0.870, Runtime: 19.90\n",
            "Test - Loss: 0.4641, Accuracy: 0.843\n",
            "Epoch: 10, Learning rate: 0.001000\n",
            "Training - Loss: 0.3615, Accuracy: 0.874, Runtime: 19.29\n",
            "Test - Loss: 0.4623, Accuracy: 0.848\n",
            "Epoch: 11, Learning rate: 0.000100\n",
            "Training - Loss: 0.3473, Accuracy: 0.878, Runtime: 21.06\n",
            "Test - Loss: 0.4577, Accuracy: 0.848\n",
            "Epoch: 12, Learning rate: 0.000100\n",
            "Training - Loss: 0.3385, Accuracy: 0.881, Runtime: 19.31\n",
            "Test - Loss: 0.4587, Accuracy: 0.848\n",
            "Epoch: 13, Learning rate: 0.000100\n",
            "Training - Loss: 0.3353, Accuracy: 0.883, Runtime: 20.57\n",
            "Test - Loss: 0.4575, Accuracy: 0.849\n",
            "Epoch: 14, Learning rate: 0.000100\n",
            "Training - Loss: 0.3395, Accuracy: 0.882, Runtime: 19.38\n",
            "Test - Loss: 0.4528, Accuracy: 0.849\n",
            "Epoch: 15, Learning rate: 0.000100\n",
            "Training - Loss: 0.3315, Accuracy: 0.884, Runtime: 19.17\n",
            "Test - Loss: 0.4542, Accuracy: 0.849\n",
            "Epoch: 16, Learning rate: 0.000010\n",
            "Training - Loss: 0.3349, Accuracy: 0.882, Runtime: 20.82\n",
            "Test - Loss: 0.4551, Accuracy: 0.849\n",
            "Epoch: 17, Learning rate: 0.000010\n",
            "Training - Loss: 0.3363, Accuracy: 0.883, Runtime: 19.01\n",
            "Test - Loss: 0.4557, Accuracy: 0.848\n",
            "Epoch: 18, Learning rate: 0.000010\n",
            "Training - Loss: 0.3360, Accuracy: 0.883, Runtime: 20.68\n",
            "Test - Loss: 0.4552, Accuracy: 0.849\n",
            "Epoch: 19, Learning rate: 0.000010\n",
            "Training - Loss: 0.3368, Accuracy: 0.882, Runtime: 18.77\n",
            "Test - Loss: 0.4573, Accuracy: 0.850\n",
            "Epoch: 20, Learning rate: 0.000010\n",
            "Training - Loss: 0.3311, Accuracy: 0.884, Runtime: 19.89\n",
            "Test - Loss: 0.4559, Accuracy: 0.849\n",
            "Done! - Runtime: 470.33 seconds\n",
            "=========\n",
            "Final loss: 0.4559, Accuracy: 0.849\n",
            "-------\n",
            "Accuracy for class: plane is 87.7 %\n",
            "Accuracy for class: car   is 90.7 %\n",
            "Accuracy for class: bird  is 80.8 %\n",
            "Accuracy for class: cat   is 69.5 %\n",
            "Accuracy for class: deer  is 86.6 %\n",
            "Accuracy for class: dog   is 74.5 %\n",
            "Accuracy for class: frog  is 91.1 %\n",
            "Accuracy for class: horse is 87.8 %\n",
            "Accuracy for class: ship  is 91.4 %\n",
            "Accuracy for class: truck is 90.1 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OrDZn3YRyE5q"
      },
      "execution_count": 19,
      "outputs": []
    }
  ]
}